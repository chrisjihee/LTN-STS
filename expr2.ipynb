{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Python check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Python path: /home/chris/miniconda3/envs/LTN/bin/python\n",
      "* Library version:\n",
      "  - numpy 1.21.5\r\n",
      "  - datasets 1.17.0\r\n",
      "  - torch 1.10.1\r\n",
      "  - LTNtorch 0.9\r\n",
      "  - transformers 4.15.0\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "python = sys.executable\n",
    "print(f\"* Python path: {python}\")\n",
    "print(f\"* Library version:\")\n",
    "!echo '  -' `$python -m pip list | grep -w numpy`\n",
    "!echo '  -' `$python -m pip list | grep -w datasets`\n",
    "!echo '  -' `$python -m pip list | grep -w torch`\n",
    "!echo '  -' `$python -m pip list | grep -w LTNtorch`\n",
    "!echo '  -' `$python -m pip list | grep -w transformers`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* data_files:\n",
      "  - train: data/klue-sts-cls/train.json\n",
      "  - valid: data/klue-sts-cls/valid.json\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "total 3764\r\n",
      "-rw-rw-r-- 1 chris chris 3690197 Dec 30 16:55 train.json\r\n",
      "-rw-rw-r-- 1 chris chris  160929 Dec 30 16:55 valid.json\r\n"
     ]
    }
   ],
   "source": [
    "from main import data_files\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(data_files['train']).parent\n",
    "\n",
    "print(f\"* data_files:\")\n",
    "for k, v in data_files.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "print('-' * 112)\n",
    "!ls -l $data_dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Env setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* available gpu_ids: (0, 1, 2, 3)\n",
      "* gpu_id: 2\n",
      "* available lang_models: \n",
      "  - bert-base-multilingual-uncased\n",
      "  - skt/kobert-base-v1\n",
      "  - monologg/koelectra-base-v3-discriminator\n",
      "  - monologg/kobigbird-bert-base\n",
      "* lang_model: monologg/koelectra-base-v3-discriminator\n"
     ]
    }
   ],
   "source": [
    "from main import gpu_ids, lang_models, do_experiment\n",
    "\n",
    "gpu_id = 2\n",
    "print(f\"* available gpu_ids: {gpu_ids}\")\n",
    "print(f\"* gpu_id: {gpu_id}\")\n",
    "\n",
    "lm_id = 2\n",
    "print(f\"* available lang_models: \")\n",
    "for m in lang_models:\n",
    "    print(f\"  - {m}\")\n",
    "print(f\"* lang_model: {lang_models[lm_id]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KLUE-STS(cls) [KoELECTRA]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[device] cuda:2 ∈ [cuda:0, cuda:1, cuda:2, cuda:3]\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b3f46ff75b254c98\n",
      "Reusing dataset json (/home/chris/.cache/huggingface/datasets/json/default-b3f46ff75b254c98/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e4f42f788e5434b8916b5e5dd333379"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[raw_datasets] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 11668\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 519\n",
      "    })\n",
      "})\n",
      "- input_columns: sentence1, sentence2\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[tokenizer(ElectraTokenizerFast)] PreTrainedTokenizerFast(name_or_path='monologg/koelectra-base-v3-discriminator', vocab_size=35000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "- text   = [CLS] 한국어 사전학습 모델을 공유합니다. [SEP]\n",
      "- tokens = ['[CLS]', '한국어', '사전', '##학습', '모델', '##을', '공유', '##합니다', '.', '[SEP]']\n",
      "- ids    = [2, 11229, 7485, 26694, 6918, 4292, 7824, 17788, 18, 3]\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4be62656641451cb80e8ca7824c8df8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "- [tokens](512)\t= ['[CLS]', '숙소', '위치', '##는', '찾기', '쉽', '##고', '일반', '##적', '##인', '한국', '##의', '반지', '##하', '숙소', '##입니다', '.', '[SEP]', '숙박', '##시설', '##의', '위치', '##는', '쉽', '##게', '...', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6e071e09a444b5cac989a586b9ffbe4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[pretrained] ElectraModel(\n",
      "  (embeddings): ElectraEmbeddings(\n",
      "    (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  ...\n",
      ")\n",
      "-      input_ids(2x512) : [2, 11229, 7485, 26694, 6918, 4292, 7824, 17788, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '...', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- attention_mask(2x512) : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '...', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- token_type_ids(2x512) : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '...', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "-  output_hidden(2x512x768) : tensor([[ 0.0427, -0.5928, -0.3165,  ..., -0.1792, -0.4459, -0.3938],\n",
      "        [ 0.7741,  0.0279, -0.5623,  ...,  0.1221,  0.2013, -0.2910],\n",
      "        [ 0.4709,  0.1436, -0.6242,  ..., -0.2247,  0.0324, -0.5515],\n",
      "        ...,\n",
      "        [-0.1424, -0.7418, -0.3524,  ..., -0.0778,  0.1921,  0.2488],\n",
      "        [-0.0301, -0.6212, -0.2604,  ...,  0.0102,  0.1351,  0.0730],\n",
      "        [ 0.0427, -0.5928, -0.3165,  ..., -0.1792, -0.4459, -0.3938]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[metric] glue/mrpc\n",
      "- GLUE, the General Language Understanding Evaluation benchmark\n",
      "================================================================================================================\n",
      "\n",
      "Epoch 01 | Loss 0.165461 | Train acc=0.9591, f1=0.9572 | Valid acc=0.8613, f1=0.8428\n",
      "Epoch 02 | Loss 0.128352 | Train acc=0.9436, f1=0.9394 | Valid acc=0.7996, f1=0.7463\n",
      "Epoch 03 | Loss 0.109846 | Train acc=0.9568, f1=0.9543 | Valid acc=0.8247, f1=0.7879\n",
      "Epoch 04 | Loss 0.115339 | Train acc=0.9589, f1=0.9584 | Valid acc=0.8150, f1=0.8147\n",
      "Epoch 05 | Loss 0.123611 | Train acc=0.9582, f1=0.9562 | Valid acc=0.8304, f1=0.8027\n",
      "Epoch 06 | Loss 0.110029 | Train acc=0.9691, f1=0.9681 | Valid acc=0.8536, f1=0.8410\n",
      "Epoch 07 | Loss 0.099944 | Train acc=0.9669, f1=0.9656 | Valid acc=0.8035, f1=0.7811\n",
      "Epoch 08 | Loss 0.150183 | Train acc=0.9671, f1=0.9664 | Valid acc=0.8015, f1=0.7968\n",
      "Epoch 09 | Loss 0.097127 | Train acc=0.9528, f1=0.9526 | Valid acc=0.7881, f1=0.7868\n",
      "Epoch 10 | Loss 0.107709 | Train acc=0.9583, f1=0.9559 | Valid acc=0.8497, f1=0.8178\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_experiment(gpu_id=gpu_id, lang_model=lang_models[lm_id], learning_rate=2e-5, max_seq_length=512, max_epoch=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[device] cuda:2 ∈ [cuda:0, cuda:1, cuda:2, cuda:3]\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b3f46ff75b254c98\n",
      "Reusing dataset json (/home/chris/.cache/huggingface/datasets/json/default-b3f46ff75b254c98/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6213e077572484e923c7f0794c04e48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[raw_datasets] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 11668\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 519\n",
      "    })\n",
      "})\n",
      "- input_columns: sentence1, sentence2\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[tokenizer(ElectraTokenizerFast)] PreTrainedTokenizerFast(name_or_path='monologg/koelectra-base-v3-discriminator', vocab_size=35000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "- text   = [CLS] 한국어 사전학습 모델을 공유합니다. [SEP]\n",
      "- tokens = ['[CLS]', '한국어', '사전', '##학습', '모델', '##을', '공유', '##합니다', '.', '[SEP]']\n",
      "- ids    = [2, 11229, 7485, 26694, 6918, 4292, 7824, 17788, 18, 3]\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "583da59bd6b7461497ec712f3b530643"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "- [tokens](512)\t= ['[CLS]', '숙소', '위치', '##는', '찾기', '쉽', '##고', '일반', '##적', '##인', '한국', '##의', '반지', '##하', '숙소', '##입니다', '.', '[SEP]', '숙박', '##시설', '##의', '위치', '##는', '쉽', '##게', '...', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10bb4b96dc89478cb3f314d93275eb85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[pretrained] ElectraModel(\n",
      "  (embeddings): ElectraEmbeddings(\n",
      "    (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  ...\n",
      ")\n",
      "-      input_ids(2x512) : [2, 11229, 7485, 26694, 6918, 4292, 7824, 17788, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '...', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- attention_mask(2x512) : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '...', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- token_type_ids(2x512) : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '...', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "-  output_hidden(2x512x768) : tensor([[ 0.0427, -0.5928, -0.3165,  ..., -0.1792, -0.4459, -0.3938],\n",
      "        [ 0.7741,  0.0279, -0.5623,  ...,  0.1221,  0.2013, -0.2910],\n",
      "        [ 0.4709,  0.1436, -0.6242,  ..., -0.2247,  0.0324, -0.5515],\n",
      "        ...,\n",
      "        [-0.1424, -0.7418, -0.3524,  ..., -0.0778,  0.1921,  0.2488],\n",
      "        [-0.0301, -0.6212, -0.2604,  ...,  0.0102,  0.1351,  0.0730],\n",
      "        [ 0.0427, -0.5928, -0.3165,  ..., -0.1792, -0.4459, -0.3938]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[metric] glue/mrpc\n",
      "- GLUE, the General Language Understanding Evaluation benchmark\n",
      "================================================================================================================\n",
      "\n",
      "Epoch 01 | Loss 0.151435 | Train acc=0.9482, f1=0.9443 | Valid acc=0.7630, f1=0.6978\n",
      "Epoch 02 | Loss 0.101278 | Train acc=0.9584, f1=0.9557 | Valid acc=0.8112, f1=0.7644\n",
      "Epoch 03 | Loss 0.093075 | Train acc=0.9650, f1=0.9630 | Valid acc=0.8189, f1=0.7793\n",
      "Epoch 04 | Loss 0.079273 | Train acc=0.9609, f1=0.9607 | Valid acc=0.7919, f1=0.8000\n",
      "Epoch 05 | Loss 0.082769 | Train acc=0.9750, f1=0.9741 | Valid acc=0.8266, f1=0.8109\n",
      "Epoch 06 | Loss 0.082595 | Train acc=0.9756, f1=0.9750 | Valid acc=0.7900, f1=0.7916\n",
      "Epoch 07 | Loss 0.068968 | Train acc=0.9769, f1=0.9760 | Valid acc=0.8015, f1=0.7756\n",
      "Epoch 08 | Loss 0.071397 | Train acc=0.9806, f1=0.9800 | Valid acc=0.8189, f1=0.8033\n",
      "Epoch 09 | Loss 0.061958 | Train acc=0.9638, f1=0.9614 | Valid acc=0.8150, f1=0.7624\n",
      "Epoch 10 | Loss 0.053967 | Train acc=0.9833, f1=0.9827 | Valid acc=0.8112, f1=0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_experiment(gpu_id=gpu_id, lang_model=lang_models[lm_id], learning_rate=1e-5, max_seq_length=512, max_epoch=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter LTN",
   "language": "python",
   "name": "ltn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}