{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Python path: /home/chris/miniconda3/envs/LTN/bin/python\n",
      "* Library version:\n",
      "  - numpy 1.21.5\n",
      "  - datasets 1.17.0\n",
      "  - torch 1.10.1\n",
      "  - LTNtorch 0.9\n",
      "  - transformers 4.15.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "python = sys.executable\n",
    "print(f\"* Python path: {python}\")\n",
    "print(f\"* Library version:\")\n",
    "!echo '  -' `$python -m pip list | grep -w numpy`\n",
    "!echo '  -' `$python -m pip list | grep -w datasets`\n",
    "!echo '  -' `$python -m pip list | grep -w torch`\n",
    "!echo '  -' `$python -m pip list | grep -w LTNtorch`\n",
    "!echo '  -' `$python -m pip list | grep -w transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/glue-mrpc:\r\n",
      "total 2076\r\n",
      "-rw-rw-r-- 1 chris chris    2803 Dec 16 17:50 info.json\r\n",
      "-rw-rw-r-- 1 chris chris  627111 Dec 16 17:50 test.json\r\n",
      "-rw-rw-r-- 1 chris chris 1337882 Dec 16 17:50 train.json\r\n",
      "-rw-rw-r-- 1 chris chris  149743 Dec 30 06:26 valid.json\r\n",
      "\r\n",
      "data/klue-sts:\r\n",
      "total 5644\r\n",
      "-rw-rw-r-- 1 chris chris    3195 Nov  3 17:35 info.json\r\n",
      "-rw-rw-r-- 1 chris chris 5526353 Nov  3 17:35 train.json\r\n",
      "-rw-rw-r-- 1 chris chris  243089 Nov  3 17:35 valid.json\r\n",
      "\r\n",
      "data/klue-sts-cls:\r\n",
      "total 3764\r\n",
      "-rw-rw-r-- 1 chris chris 3690197 Dec 30 06:52 train.json\r\n",
      "-rw-rw-r-- 1 chris chris  160929 Dec 30 06:52 valid.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/*\n",
    "\n",
    "from main import do_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLUE-STS(binary classification) [mini, KoELECTRA-<font color='red'>Small</font>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1853665244ca6901\n",
      "Reusing dataset json (/home/chris/.cache/huggingface/datasets/json/default-1853665244ca6901/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abefa5391584eecbddaec994cdbf726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[raw_datasets] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 50\n",
      "    })\n",
      "})\n",
      "- input_columns: sentence1, sentence2\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[tokenizer] PreTrainedTokenizer(name_or_path='monologg/koelectra-small-v3-discriminator', vocab_size=35000, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5980c7eaf224fa78d4b36392025a14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "- [tokens](128)\t= ['[CLS]', '숙소', '위치', '##는', '찾기', '쉽', '##고', '일반', '##적', '##인', '한국', '##의', '반지', '##하', '숙소', '##입니다', '.', '[SEP]', '숙박', '##시설', '##의', '위치', '##는', '쉽', '##게', '찾', '##을', '수', '있', '##고', '한국', '##의', '대표', '##적', '##인', '반지', '##하', '숙박', '##시설', '##입니다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1066212c574f328d602d7396dac6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[pretrained] ElectraModel(\n",
      "  (embeddings): ElectraEmbeddings(\n",
      "    (word_embeddings): Embedding(35000, 128, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 128)\n",
      "    (token_type_embeddings): Embedding(2, 128)\n",
      "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[metric] glue/mrpc\n",
      "- GLUE, the General Language Understanding Evaluation benchmark\n",
      "================================================================================================================\n",
      "\n",
      "Epoch 01 | Loss 0.497938 | Train acc=0.6200, f1=0.4062 | Valid acc=0.5600, f1=0.3125\n",
      "Epoch 02 | Loss 0.493213 | Train acc=0.7400, f1=0.6176 | Valid acc=0.6000, f1=0.2857\n",
      "Epoch 03 | Loss 0.483598 | Train acc=0.8400, f1=0.8000 | Valid acc=0.6000, f1=0.5000\n",
      "Epoch 04 | Loss 0.468769 | Train acc=0.9200, f1=0.8947 | Valid acc=0.6600, f1=0.6222\n",
      "Epoch 05 | Loss 0.447646 | Train acc=0.9700, f1=0.9620 | Valid acc=0.7000, f1=0.6667\n",
      "Epoch 06 | Loss 0.415276 | Train acc=0.9900, f1=0.9877 | Valid acc=0.6400, f1=0.6250\n",
      "Epoch 07 | Loss 0.371739 | Train acc=1.0000, f1=1.0000 | Valid acc=0.6400, f1=0.6667\n",
      "Epoch 08 | Loss 0.327149 | Train acc=1.0000, f1=1.0000 | Valid acc=0.6400, f1=0.6400\n",
      "Epoch 09 | Loss 0.278993 | Train acc=1.0000, f1=1.0000 | Valid acc=0.6600, f1=0.6531\n",
      "Epoch 10 | Loss 0.239217 | Train acc=1.0000, f1=1.0000 | Valid acc=0.6400, f1=0.6400\n"
     ]
    }
   ],
   "source": [
    "do_experiment(data_files={\n",
    "    \"train\": \"data/klue-sts-cls/train.json\",\n",
    "    \"valid\": \"data/klue-sts-cls/valid.json\",\n",
    "}, pretrained=\"monologg/koelectra-small-v3-discriminator\", max_epoch=10, max_seq_length=128, num_train_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLUE-STS(binary classification) [full, KoELECTRA-<font color='red'>Small</font>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1853665244ca6901\n",
      "Reusing dataset json (/home/chris/.cache/huggingface/datasets/json/default-1853665244ca6901/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee82384256a74ce2a96d13f17f01b8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[raw_datasets] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 11668\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 519\n",
      "    })\n",
      "})\n",
      "- input_columns: sentence1, sentence2\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[tokenizer] PreTrainedTokenizer(name_or_path='monologg/koelectra-small-v3-discriminator', vocab_size=35000, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4243cbf024fe44f08a3599ff88a4a537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "- [tokens](256)\t= ['[CLS]', '숙소', '위치', '##는', '찾기', '쉽', '##고', '일반', '##적', '##인', '한국', '##의', '반지', '##하', '숙소', '##입니다', '.', '[SEP]', '숙박', '##시설', '##의', '위치', '##는', '쉽', '##게', '찾', '##을', '수', '있', '##고', '한국', '##의', '대표', '##적', '##인', '반지', '##하', '숙박', '##시설', '##입니다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917dcf7fc16e459cb00bf2a519630454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[pretrained] ElectraModel(\n",
      "  (embeddings): ElectraEmbeddings(\n",
      "    (word_embeddings): Embedding(35000, 128, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 128)\n",
      "    (token_type_embeddings): Embedding(2, 128)\n",
      "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[metric] glue/mrpc\n",
      "- GLUE, the General Language Understanding Evaluation benchmark\n",
      "================================================================================================================\n",
      "\n",
      "Epoch 01 | Loss 0.186109 | Train acc=0.9613, f1=0.9603 | Valid acc=0.7457, f1=0.7317\n",
      "Epoch 02 | Loss 0.108076 | Train acc=0.9637, f1=0.9619 | Valid acc=0.7592, f1=0.7126\n",
      "Epoch 03 | Loss 0.093838 | Train acc=0.9716, f1=0.9706 | Valid acc=0.7861, f1=0.7643\n",
      "Epoch 04 | Loss 0.078927 | Train acc=0.9487, f1=0.9447 | Valid acc=0.7707, f1=0.7032\n",
      "Epoch 05 | Loss 0.084198 | Train acc=0.9747, f1=0.9740 | Valid acc=0.7900, f1=0.7771\n",
      "Epoch 06 | Loss 0.077033 | Train acc=0.9717, f1=0.9705 | Valid acc=0.7572, f1=0.7123\n",
      "Epoch 07 | Loss 0.070947 | Train acc=0.9721, f1=0.9709 | Valid acc=0.7803, f1=0.7444\n",
      "Epoch 08 | Loss 0.067471 | Train acc=0.9419, f1=0.9367 | Valid acc=0.7592, f1=0.6667\n",
      "Epoch 09 | Loss 0.066973 | Train acc=0.9750, f1=0.9740 | Valid acc=0.7996, f1=0.7679\n",
      "Epoch 10 | Loss 0.059842 | Train acc=0.9795, f1=0.9789 | Valid acc=0.8092, f1=0.7916\n"
     ]
    }
   ],
   "source": [
    "do_experiment(data_files={\n",
    "    \"train\": \"data/klue-sts-cls/train.json\",\n",
    "    \"valid\": \"data/klue-sts-cls/valid.json\",\n",
    "}, pretrained=\"monologg/koelectra-small-v3-discriminator\", max_epoch=10, max_seq_length=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLUE-STS(binary classification) [full, KoELECTRA-<font color='red'>Base</font>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1853665244ca6901\n",
      "Reusing dataset json (/home/chris/.cache/huggingface/datasets/json/default-1853665244ca6901/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af19997349a04367b6b201c28e81a049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[raw_datasets] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 11668\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['guid', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 519\n",
      "    })\n",
      "})\n",
      "- input_columns: sentence1, sentence2\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[tokenizer] PreTrainedTokenizer(name_or_path='monologg/koelectra-base-v3-discriminator', vocab_size=35000, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a274cd21094943801e4d5168701c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "- [tokens](256)\t= ['[CLS]', '숙소', '위치', '##는', '찾기', '쉽', '##고', '일반', '##적', '##인', '한국', '##의', '반지', '##하', '숙소', '##입니다', '.', '[SEP]', '숙박', '##시설', '##의', '위치', '##는', '쉽', '##게', '찾', '##을', '수', '있', '##고', '한국', '##의', '대표', '##적', '##인', '반지', '##하', '숙박', '##시설', '##입니다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29148edf516f438cade4d3478e60a78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================================\n",
      "[pretrained] ElectraModel(\n",
      "  (embeddings): ElectraEmbeddings(\n",
      "    (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "[metric] glue/mrpc\n",
      "- GLUE, the General Language Understanding Evaluation benchmark\n",
      "================================================================================================================\n",
      "\n",
      "Epoch 01 | Loss 0.153669 | Train acc=0.9535, f1=0.9534 | Valid acc=0.7861, f1=0.7948\n",
      "Epoch 02 | Loss 0.100943 | Train acc=0.9663, f1=0.9649 | Valid acc=0.8247, f1=0.8051\n"
     ]
    }
   ],
   "source": [
    "do_experiment(data_files={\n",
    "    \"train\": \"data/klue-sts-cls/train.json\",\n",
    "    \"valid\": \"data/klue-sts-cls/valid.json\",\n",
    "}, pretrained=\"monologg/koelectra-base-v3-discriminator\", max_epoch=10, max_seq_length=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter LTN",
   "language": "python",
   "name": "ltn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}